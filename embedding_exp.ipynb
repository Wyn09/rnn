{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(10, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9}\n"
     ]
    }
   ],
   "source": [
    "# 文本字典\n",
    "sets = [chr(ord(\"a\") + i) for i in range(10)]\n",
    "vocab = {c:i for i,c in enumerate(sets)}\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 3], [8, 2, 4], [1, 4, 4]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词汇表输入数据\n",
    "words = [\"bed\", \"ice\", \"bee\"]\n",
    "token_index = [[vocab[c] for c in w] for w in words]\n",
    "token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 3],\n",
      "        [8, 2, 4],\n",
      "        [1, 4, 4]])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.tensor(token_index)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.],\n",
      "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2.],\n",
      "        [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "         3., 3.],\n",
      "        [4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
      "         4., 4.],\n",
      "        [5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
      "         5., 5.],\n",
      "        [6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
      "         6., 6.],\n",
      "        [7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n",
      "         7., 7.],\n",
      "        [8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
      "         8., 8.],\n",
      "        [9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.,\n",
      "         9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    emb.weight.data[i] = i\n",
    "print(emb.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1.],\n",
       "          [4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "           4., 4., 4.],\n",
       "          [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "           3., 3., 3.]],\n",
       " \n",
       "         [[8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,\n",
       "           8., 8., 8.],\n",
       "          [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "           2., 2., 2.],\n",
       "          [4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "           4., 4., 4.]],\n",
       " \n",
       "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1.],\n",
       "          [4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "           4., 4., 4.],\n",
       "          [4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "           4., 4., 4.]]], grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([3, 3, 20]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = emb(input_data)\n",
    "result,result.shape # (batch_size, seq_len, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2 = nn.Embedding(10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', 'and', 'of', 'having', 'nothing', 'to', 'do', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', 'thought', 'alice', 'without', 'pictures', 'or', 'conversation', 'so', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', 'as', 'well', 'as', 'she', 'could', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy', 'chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', 'when', 'suddenly', 'a', 'white', 'rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenize(text)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokens)\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     43\u001b[0m word_to_ix, ix_to_word \u001b[38;5;241m=\u001b[39m build_vocab(tokens, min_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m encoded_tokens \u001b[38;5;241m=\u001b[39m encode_tokens(tokens, word_to_ix)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# 1. 数据准备\n",
    "text = \"\"\"\n",
    "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: \n",
    "once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, \n",
    "'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
    "So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid),\n",
    "whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, \n",
    "when suddenly a White Rabbit with pink eyes ran close by her.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    # 简单的分词方法，您可以根据需要使用更复杂的分词器\n",
    "    text = text.lower()\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "    return tokens\n",
    "\n",
    "def build_vocab(tokens, min_freq=1):\n",
    "    counter = Counter(tokens)\n",
    "    vocab = {word for word, freq in counter.items() if freq >= min_freq}\n",
    "    # 添加特殊符号\n",
    "    vocab = ['<pad>', '<unk>'] + sorted(vocab)\n",
    "    word_to_ix = {word: idx for idx, word in enumerate(vocab)}\n",
    "    ix_to_word = {idx: word for word, idx in word_to_ix.items()}\n",
    "    return word_to_ix, ix_to_word\n",
    "\n",
    "def encode_tokens(tokens, word_to_ix):\n",
    "    return [word_to_ix.get(token, word_to_ix['<unk>']) for token in tokens]\n",
    "\n",
    "# 加载和处理数据\n",
    "# text = load_text('data.txt')\n",
    "tokens = tokenize(text)\n",
    "\n",
    "word_to_ix, ix_to_word = build_vocab(tokens, min_freq=1)\n",
    "encoded_tokens = encode_tokens(tokens, word_to_ix)\n",
    "\n",
    "vocab_size = len(word_to_ix)\n",
    "print(f\"词汇表大小: {vocab_size}\")\n",
    "\n",
    "# 3. 创建输入和目标对\n",
    "def create_context_targets(encoded_tokens, context_size=2):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(len(encoded_tokens) - context_size):\n",
    "        context = encoded_tokens[i:i+context_size]\n",
    "        target = encoded_tokens[i+context_size]\n",
    "        inputs.append(context)\n",
    "        targets.append(target)\n",
    "    return inputs, targets\n",
    "\n",
    "context_size = 2\n",
    "inputs, targets = create_context_targets(encoded_tokens, context_size)\n",
    "print(f\"样本数量: {len(inputs)}\")\n",
    "\n",
    "# 4. 定义词矩阵表示\n",
    "embedding_dim_matrix = (5, 5)  # 5x5 矩阵\n",
    "\n",
    "class WordMatrixEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, matrix_size):\n",
    "        super(WordMatrixEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, matrix_size[0] * matrix_size[1])\n",
    "        self.matrix_size = matrix_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_length)\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, 25)\n",
    "        embedded = embedded.view(-1, x.size(1), *self.matrix_size)  # (batch_size, seq_length, 5, 5)\n",
    "        return embedded\n",
    "\n",
    "# 5. 定义自定义数据集类\n",
    "class LanguageModelingDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 返回输入序列和目标词\n",
    "        return torch.tensor(self.inputs[idx], dtype=torch.long), torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "\n",
    "# 6. 创建数据加载器\n",
    "batch_size = 16\n",
    "dataset = LanguageModelingDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 7. 定义包含卷积层的 RNN 模型\n",
    "class CNN_RNN_Model(nn.Module):\n",
    "    def __init__(self, vocab_size, matrix_size, conv_out_channels, conv_kernel_size, hidden_size, output_size):\n",
    "        super(CNN_RNN_Model, self).__init__()\n",
    "        self.word_matrix_embedding = WordMatrixEmbedding(vocab_size, matrix_size)\n",
    "        self.conv = nn.Conv2d(in_channels=1, \n",
    "                              out_channels=conv_out_channels, \n",
    "                              kernel_size=conv_kernel_size)\n",
    "        # 计算卷积输出的尺寸\n",
    "        conv_height = matrix_size[0] - conv_kernel_size + 1\n",
    "        conv_width = matrix_size[1] - conv_kernel_size + 1\n",
    "        self.flatten_size = conv_out_channels * conv_height * conv_width\n",
    "        self.lstm = nn.LSTM(input_size=self.flatten_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_length)\n",
    "        \"\"\"\n",
    "        batch_size, seq_length = x.size()\n",
    "        # 词矩阵嵌入\n",
    "        embedded = self.word_matrix_embedding(x)  # (batch_size, seq_length, 5, 5)\n",
    "        # 添加一个维度作为通道维度\n",
    "        embedded = embedded.unsqueeze(2)  # (batch_size, seq_length, 1, 5, 5)\n",
    "        # 重塑以适应 Conv2d 输入要求\n",
    "        embedded = embedded.view(batch_size * seq_length, 1, *self.word_matrix_embedding.matrix_size)  # (batch_size * seq_length, 1, 5, 5)\n",
    "        # 卷积操作\n",
    "        conv_out = self.conv(embedded)  # (batch_size * seq_length, conv_out_channels, H_out, W_out)\n",
    "        conv_out = torch.relu(conv_out)\n",
    "        # 展平\n",
    "        conv_out = conv_out.view(batch_size, seq_length, -1)  # (batch_size, seq_length, flatten_size)\n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(conv_out)  # (batch_size, seq_length, hidden_size)\n",
    "        # 取最后一个时间步的输出\n",
    "        lstm_out = lstm_out[:, -1, :]  # (batch_size, hidden_size)\n",
    "        # 全连接层\n",
    "        output = self.fc(lstm_out)  # (batch_size, output_size)\n",
    "        return output\n",
    "\n",
    "# 8. 初始化模型、损失函数和优化器\n",
    "conv_out_channels = 16\n",
    "conv_kernel_size = 3\n",
    "hidden_size = 128\n",
    "output_size = vocab_size\n",
    "\n",
    "model = CNN_RNN_Model(\n",
    "    vocab_size=vocab_size,\n",
    "    matrix_size=embedding_dim_matrix,\n",
    "    conv_out_channels=conv_out_channels,\n",
    "    conv_kernel_size=conv_kernel_size,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size\n",
    ")\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 9. 训练模型\n",
    "num_epochs = 20  # 根据数据集大小和计算资源调整\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# 10. 测试模型\n",
    "def predict(model, word_to_ix, ix_to_word, context, device, top_k=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenize(context)\n",
    "        indices = [word_to_ix.get(token, word_to_ix['<unk>']) for token in tokens]\n",
    "        if len(indices) < context_size:\n",
    "            # 填充\n",
    "            indices = [word_to_ix['<pad>']] * (context_size - len(indices)) + indices\n",
    "        else:\n",
    "            indices = indices[-context_size:]\n",
    "        input_tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)  # (1, context_size)\n",
    "        output = model(input_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        top_probs, top_idxs = torch.topk(probabilities, top_k)\n",
    "        top_probs = top_probs.cpu().numpy().flatten()\n",
    "        top_idxs = top_idxs.cpu().numpy().flatten()\n",
    "        predictions = [(ix_to_word[idx], prob) for idx, prob in zip(top_idxs, top_probs)]\n",
    "        return predictions\n",
    "\n",
    "# 示例上下文\n",
    "contexts = [\n",
    "    \"alice was\",\n",
    "    \"she had\",\n",
    "    \"the book\",\n",
    "    \"what is\",\n",
    "    \"a book\",\n",
    "    \"to get very\"\n",
    "]\n",
    "\n",
    "for context in contexts:\n",
    "    predictions = predict(model, word_to_ix, ix_to_word, context, device)\n",
    "    predicted_words = \", \".join([f\"{word} ({prob:.2f})\" for word, prob in predictions])\n",
    "    print(f'Context: \"{context}\" -> Predicted Next Words: {predicted_words}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
